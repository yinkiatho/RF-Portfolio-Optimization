{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "DATA_DIR = (os.getcwd() + \"/data/\")\n",
    "start_date = '1999-01-01'\n",
    "end_date = \"2019-12-31\"\n",
    "# Get fundamental data for each stock in the ticker and append to the dataframe\n",
    "\n",
    "\n",
    "def get_all_symbols():\n",
    "    return [v.strip('.csv') for v in os.listdir(DATA_DIR)]\n",
    "\n",
    "\n",
    "tickers = get_all_symbols()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "tickers = ['AAPL']\n",
    "for ticker in tickers:\n",
    "    ticker_data = pd.read_csv(f\"data/{ticker}.csv\", index_col=0)\n",
    "    ticker_data['Next Day Close'] = ticker_data['Close'].shift(-1)\n",
    "    ticker_data.dropna(inplace=True)\n",
    "    # print(ticker_data.head())\n",
    "    features = ticker_data[['Volume', 'Close',\n",
    "                            'Returns', 'Short Term Reversal', 'Stock Momentum',\n",
    "                            'Long Term Reversal', 'Market_Beta', 'Turnover Volatility', 'Dividends',\n",
    "                            'Total Returns', 'Total Return Volatility', 'SMA_5', 'SMA_20', 'SMA_50',\n",
    "                            'SMA_252', 'adv20', 'VWAP', 'log_returns', 'volatility_30',\n",
    "                            'volatility_60', 'annual_volatility', 'RSI(2)', 'RSI(7)', 'RSI(14)',\n",
    "                            'CCI(30)', 'CCI(50)', 'CCI(100)', 'BBWidth', 'Williams']]\n",
    "\n",
    "    target = ticker_data['Next Day Close']\n",
    "\n",
    "    X = np.array(features).reshape(-1, 29)  # input as columns\n",
    "    y = np.array(target)  # output as rows\n",
    "\n",
    "    feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Building RF model\n",
    "    random_forest = RandomForestRegressor(\n",
    "        n_jobs=-1, random_state=123, oob_score=True)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 125, 130, 150],\n",
    "        'max_depth': [15, 10, 20, 25, None],\n",
    "        'min_samples_leaf': [75, 100, 125],\n",
    "        'criterion': ['absolute_error', 'squared_error', 'friedman_mse'],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=random_forest, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(feature_train, target_train)\n",
    "\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    criterion, max_depth, max_features, min_samples_leaf, n_estimators = grid_search.best_params_.values()\n",
    "\n",
    "    # Building MLP model\n",
    "    mlp = MLPRegressor(max_iter=1000)\n",
    "\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50, 50), (100, 50, 25), (100, 100), (50, 50, 50)],\n",
    "        'activation': ['relu', 'tanh', 'identity'],\n",
    "        # 'learning_rate': ['constant', 'adaptive'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV instance\n",
    "    grid_search = GridSearchCV(mlp, param_grid, cv=5,\n",
    "                               n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Fit the GridSearchCV to find the best hyperparameters\n",
    "    grid_search.fit(feature_train, target_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "    base_models = [\n",
    "        ('rf', RandomForestRegressor(criterion=criterion, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, n_estimators=n_estimators,\n",
    "                                     oob_score=True, random_state=123, n_jobs=-1)),\n",
    "        ('nn', MLPRegressor(max_iter=1000, **best_params))\n",
    "    ]\n",
    "\n",
    "    # base_models = [\n",
    "    #    ('rf', RandomForestRegressor(criterion='absolute_error', max_depth=10, max_features='sqrt', min_samples_leaf=75, n_estimators=130,\n",
    "    #                                 oob_score=True, random_state=123, n_jobs=-1)),\n",
    "    #    ('nn', MLPRegressor(max_iter=1000, activation='tanh', alpha=0.001, hidden_layer_sizes=(50, 50, 50)))\n",
    "    # ]\n",
    "\n",
    "    meta_learner = GradientBoostingRegressor(\n",
    "        random_state=42, n_estimators=750, learning_rate=0.01, max_depth=5, max_features='sqrt')\n",
    "    stack_model = StackingRegressor(\n",
    "        estimators=base_models, final_estimator=meta_learner)\n",
    "\n",
    "    # Grid Search for meta learner\n",
    "    param_grid = {\n",
    "        'final_estimator__n_estimators': [250, 225, 275],\n",
    "        'final_estimator__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        # Example parameter choices\n",
    "        'final_estimator__max_depth': [6, 5, 8, None]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=stack_model, param_grid=param_grid,\n",
    "                               cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(feature_train, target_train)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # best_params = grid_search.best_params_\n",
    "    best_meta_learner = grid_search.best_estimator_\n",
    "\n",
    "    final_stack_model = StackingRegressor(\n",
    "        estimators=base_models, final_estimator=best_meta_learner)\n",
    "    # Fit the stacking model on the training data\n",
    "    final_stack_model.fit(feature_train, target_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred = final_stack_model.predict(feature_test)\n",
    "\n",
    "    # print(confusion_matrix(target_test, grid_search_predictions))\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(target_test, y_pred)}\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(target_test, y_pred)}\")\n",
    "    print(f\"R^2: {r2_score(target_test, y_pred)}\")\n",
    "\n",
    "    # Add the predictions to the dataframe only for the test data, avoid look ahead bias\n",
    "    ticker_data['Next Day Close Predictions'] = np.nan\n",
    "    ticker_data.iloc[-len(y_pred):,\n",
    "                     ticker_data.columns.get_loc('Next Day Close Predictions')] = y_pred\n",
    "    ticker_data[['Next Day Close', 'Next Day Close Predictions']].plot(\n",
    "        figsize=(15, 5))\n",
    "\n",
    "    data = ticker_data[['Next Day Close', 'Next Day Close Predictions']]\n",
    "    data.dropna(inplace=True)\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data.resample('M').prod().plot(figsize=(15, 5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
